{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/train_features.tsv\", sep = '\\t')\n",
    "val_data = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/valid_features.tsv\", sep = '\\t')\n",
    "test_data = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/test_features.csv\")\n",
    "test_data_final = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/train_labels.tsv\", sep = '\\t')\n",
    "val_labels = pd.read_csv(\"/Users/varunsai/Desktop/IML/Assignment-2/data/valid_labels.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['movieId','YTId'], axis=1, inplace=True)\n",
    "val_data.drop(['movieId','YTId'], axis=1, inplace=True)\n",
    "test_data.drop(['movieId','YTId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tag']=train_data['tag'].apply(lambda word:re.sub('[^a-zA-Z]',' ',word))\n",
    "val_data['tag']=val_data['tag'].apply(lambda word:re.sub('[^a-zA-Z]',' ',word))\n",
    "test_data['tag']=test_data['tag'].apply(lambda word:re.sub('[^a-zA-Z]',' ',word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['title']=train_data['title'].apply(lambda word:re.sub('[^a-zA-Z]',' ',str(word)))\n",
    "val_data['title']=val_data['title'].apply(lambda word:re.sub('[^a-zA-Z]',' ',str(word)))\n",
    "test_data['title']=test_data['title'].apply(lambda word:re.sub('[^a-zA-Z]',' ',str(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels['genres']\n",
    "val_labels = val_labels['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def stem_tokens(inp):\n",
    "    words = [wl.lemmatize(word) for word in inp.split()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(tokenizer=stem_tokens, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag = word_vectorizer.fit_transform(train_data['tag'].tolist())\n",
    "val_tag = word_vectorizer.transform(val_data['tag'].tolist())\n",
    "test_tag = word_vectorizer.transform(test_data['tag'].tolist())\n",
    "#word_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title = word_vectorizer.fit_transform(train_data['title'].tolist())\n",
    "val_title = word_vectorizer.transform(val_data['title'].tolist())\n",
    "test_title = word_vectorizer.transform(test_data['title'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df = pd.DataFrame(train_tag.toarray())\n",
    "val_tag_df = pd.DataFrame(val_tag.toarray())\n",
    "test_tag_df = pd.DataFrame(test_tag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_df = pd.DataFrame(train_title.toarray())\n",
    "val_title_df = pd.DataFrame(val_title.toarray())\n",
    "test_title_df = pd.DataFrame(test_title.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['title','tag','year'], axis=1, inplace=True)\n",
    "val_data.drop(['title','tag','year'], axis=1, inplace=True)\n",
    "test_data.drop(['title','tag','year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data,train_tag_df,train_title_df], axis=1)\n",
    "val_data = pd.concat([val_data,val_tag_df,val_title_df], axis=1)\n",
    "test_data = pd.concat([test_data,test_tag_df,test_title_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csr(df):\n",
    "    arr = lil_matrix(df.shape, dtype=np.float32)\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ix = df[col] != 0\n",
    "        arr[np.where(ix), i] = 1\n",
    "\n",
    "    return arr.tocsr()\n",
    "\n",
    "y_train = train_labels\n",
    "X_train = df_to_csr(train_data)\n",
    "\n",
    "y_val = val_labels\n",
    "X_val = df_to_csr(val_data)\n",
    "\n",
    "X_test = df_to_csr(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val_nb = nb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = classification_report(prediction_val_nb, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         0\n",
      "   Adventure       0.00      0.00      0.00         0\n",
      "   Animation       0.00      0.00      0.00         0\n",
      "    Children       0.00      0.00      0.00         0\n",
      "      Comedy       0.53      0.36      0.43        56\n",
      "       Crime       0.00      0.00      0.00         0\n",
      " Documentary       0.06      1.00      0.11         1\n",
      "       Drama       0.72      0.23      0.35       132\n",
      "     Fantasy       0.22      1.00      0.36         4\n",
      "   Film_Noir       0.00      0.00      0.00         0\n",
      "      Horror       0.00      0.00      0.00         0\n",
      "     Musical       0.00      0.00      0.00         0\n",
      "     Mystery       0.00      0.00      0.00         0\n",
      "     Romance       0.35      0.35      0.35        51\n",
      "      Sci_Fi       0.62      0.71      0.67        14\n",
      "    Thriller       0.50      0.36      0.42        39\n",
      "         War       0.10      1.00      0.17         2\n",
      "     Western       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       299\n",
      "   macro avg       0.17      0.28      0.16       299\n",
      "weighted avg       0.58      0.33      0.39       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\",decision_function_shape='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val_svm = svm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = classification_report(prediction_val_svm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.17      0.50      0.25         2\n",
      "   Adventure       0.50      0.20      0.29         5\n",
      "   Animation       0.33      0.33      0.33         3\n",
      "    Children       0.33      0.11      0.17         9\n",
      "      Comedy       0.45      0.39      0.41        44\n",
      "       Crime       0.20      0.20      0.20         5\n",
      " Documentary       0.61      0.55      0.58        20\n",
      "       Drama       0.53      0.32      0.40        71\n",
      "     Fantasy       0.22      0.33      0.27        12\n",
      "   Film_Noir       0.00      0.00      0.00         2\n",
      "      Horror       0.38      0.30      0.33        10\n",
      "     Musical       0.10      0.12      0.11         8\n",
      "     Mystery       0.11      0.29      0.16         7\n",
      "     Romance       0.33      0.36      0.35        47\n",
      "      Sci_Fi       0.56      0.64      0.60        14\n",
      "    Thriller       0.21      0.20      0.21        30\n",
      "         War       0.38      0.80      0.52        10\n",
      "     Western       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35       299\n",
      "   macro avg       0.30      0.31      0.29       299\n",
      "weighted avg       0.40      0.35      0.36       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val_gbc = gbc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_gbc = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = classification_report(prediction_val_gbc, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         1\n",
      "   Adventure       0.00      0.00      0.00         3\n",
      "   Animation       0.33      0.33      0.33         3\n",
      "    Children       0.00      0.00      0.00         0\n",
      "      Comedy       0.47      0.49      0.48        37\n",
      "       Crime       0.40      0.33      0.36         6\n",
      " Documentary       0.44      0.53      0.48        15\n",
      "       Drama       0.51      0.21      0.30       105\n",
      "     Fantasy       0.33      0.60      0.43        10\n",
      "   Film_Noir       0.25      0.20      0.22         5\n",
      "      Horror       0.38      0.75      0.50         4\n",
      "     Musical       0.20      0.25      0.22         8\n",
      "     Mystery       0.22      0.67      0.33         6\n",
      "     Romance       0.25      0.36      0.30        36\n",
      "      Sci_Fi       0.69      0.69      0.69        16\n",
      "    Thriller       0.32      0.36      0.34        25\n",
      "         War       0.43      0.50      0.46        18\n",
      "     Western       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       299\n",
      "   macro avg       0.29      0.35      0.30       299\n",
      "weighted avg       0.42      0.36      0.37       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val_dt = dt.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = classification_report(prediction_val_dt, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         4\n",
      "   Adventure       0.00      0.00      0.00         3\n",
      "   Animation       0.00      0.00      0.00         1\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.45      0.47      0.46        36\n",
      "       Crime       0.20      0.25      0.22         4\n",
      " Documentary       0.39      0.64      0.48        11\n",
      "       Drama       0.42      0.30      0.35        60\n",
      "     Fantasy       0.28      0.31      0.29        16\n",
      "   Film_Noir       0.25      1.00      0.40         1\n",
      "      Horror       0.12      0.12      0.12         8\n",
      "     Musical       0.10      0.11      0.11         9\n",
      "     Mystery       0.00      0.00      0.00         4\n",
      "     Romance       0.43      0.36      0.39        61\n",
      "      Sci_Fi       0.69      0.50      0.58        22\n",
      "    Thriller       0.50      0.35      0.41        40\n",
      "         War       0.38      0.57      0.46        14\n",
      "     Western       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35       299\n",
      "   macro avg       0.23      0.28      0.24       299\n",
      "weighted avg       0.40      0.35      0.37       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output for kaggle test\n",
    "#prediction_kaggle variable can take test prediction of any of the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_kaggle = pd.DataFrame(prediction_test_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_final['genres'] = prediction_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.DataFrame(test_data_final,columns = [\"movieId\", \"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.to_csv(\"/Users/varunsai/Desktop/kaggle.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
